{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "493068b4",
   "metadata": {},
   "source": [
    "# Explore label inference confidence\n",
    "Designed to be run on the **staging** dataset (though it should be able to run on whatever).\n",
    "The goal is to be able to make an informed decision on what confidence threshold we should use in the staging test of the new Label UI.\n",
    "We first examine one user's data, then try to generalize our findings to the whole dataset.\n",
    "Portions of this notebook inspired by/copypasted from `Evaluate sim wrt filtration and different radii - unrolled`. Once one inputs a UUID immediately below, the notebook can be run top to bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5a8299",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2d1ab4",
   "metadata": {},
   "source": [
    "### Set target user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c2170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import UUID\n",
    "target_user = UUID(input(\"Enter target UUID: \"))  # To avoid accidentally leaving real UUIDs in the notebook\n",
    "print(target_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c847bc16",
   "metadata": {},
   "source": [
    "### Do not truncate dataframes to print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57f4d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.width\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428a8dd0",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Substantially copypasted from `Evaluate sim wrt filtration and different radii - unrolled`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc4f955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything we could possibly want\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geojson as gj\n",
    "import sklearn.cluster as sc\n",
    "import sklearn.metrics.pairwise as smp\n",
    "import sklearn.metrics as sm\n",
    "\n",
    "import json\n",
    "import copy\n",
    "import itertools\n",
    "\n",
    "import folium\n",
    "import branca.element as bre\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as pltc\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython import display\n",
    "from uuid import UUID\n",
    "\n",
    "import bson.json_util as bju\n",
    "import bson.objectid as boi\n",
    "\n",
    "import emission.storage.timeseries.abstract_timeseries as esta\n",
    "import emission.storage.decorations.trip_queries as esdtq\n",
    "import emission.analysis.modelling.tour_model.similarity as eamts\n",
    "\n",
    "import emission.core.wrapper.entry as ecwe\n",
    "import emission.core.wrapper.confirmedtrip as ecwct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c127bd9",
   "metadata": {},
   "source": [
    "## Read the data\n",
    "Substantially copypasted from `Evaluate sim wrt filtration and different radii - unrolled`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943487e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users = esta.TimeSeries.get_uuid_list()\n",
    "confirmed_trip_df_map = {}\n",
    "labeled_trip_df_map = {}\n",
    "expanded_trip_df_map = {}\n",
    "for u in all_users:\n",
    "    ts = esta.TimeSeries.get_time_series(u)\n",
    "    ct_df = ts.get_data_df(\"analysis/confirmed_trip\")\n",
    "    confirmed_trip_df_map[u] = ct_df\n",
    "    # We'll use this filtering and expansion for our individual user exploration, but when we do things in aggregate we'll do our own processing directly from confirmed_trip_df_map\n",
    "    labeled_trip_df_map[u] = esdtq.filter_labeled_trips(ct_df)\n",
    "    expanded_trip_df_map[u] = esdtq.expand_userinputs(labeled_trip_df_map[u])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cefad3",
   "metadata": {},
   "source": [
    "## Define our own processing functions\n",
    "Not particularly pretty, but they get the job done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eb17ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_NAMES = [\"mode_confirm\", \"purpose_confirm\", \"replaced_mode\"]\n",
    "EMPTY_INFERENCE = {\"labels\": {}, \"p\": 0.0}\n",
    "\n",
    "# Provides a measure of the difference between two dictionaries, passed in as a single indexable argument (in practice, a Series)\n",
    "def dict_diff(ds):\n",
    "    items0, items1 = ds[0].items(), ds[1].items()\n",
    "    if len(items0) > 0 and len(items1) > 0:\n",
    "        return len(set(items0) ^ set(items1))//2\n",
    "    else:\n",
    "        return max(len(items0), len(items1))\n",
    "\n",
    "def handle_empty(col):\n",
    "    return col if len(col) > 0 else []\n",
    "\n",
    "def label_dict(e):\n",
    "    return {n: e[\"user_input\"][n] if n in e[\"user_input\"] else None for n in LABEL_NAMES}\n",
    "\n",
    "def label_tuple(e):\n",
    "    return tuple(e[\"user_input\"][n] if n in e[\"user_input\"] else None for n in LABEL_NAMES)\n",
    "\n",
    "# Operates in-place on a DataFrame of trips\n",
    "def process_trips(trips):\n",
    "    # If there's no data, add the column names anyway so we can reference them later\n",
    "    if len(trips.axes[1]) == 0:\n",
    "        for col_name in [\"all_user_labels_dict\", \"all_user_labels\", \"most_likely_inference_dict\", \"most_likely_inference\", \"mli_confidence\", \"correct\", \"mismatches\"]:\n",
    "            trips[col_name] = []\n",
    "        return\n",
    "    \n",
    "    inferred = trips[\"inferred_labels\"]\n",
    "    most_likely = [max([e for e in inf], key = lambda e : e[\"p\"]) if len(inf) > 0 else EMPTY_INFERENCE for inf in inferred]\n",
    "    confidences = [ent[\"p\"] if ent is not None else 0.0 for ent in most_likely]\n",
    "    trips[\"all_user_labels_dict\"] = handle_empty([label_dict(e) for _,e in trips.iterrows()])\n",
    "    trips[\"all_user_labels\"] = handle_empty([label_tuple(e) for _,e in trips.iterrows()])\n",
    "    trips[\"most_likely_inference_dict\"] = handle_empty([e[\"labels\"] for e in most_likely])\n",
    "    trips[\"most_likely_inference\"] = handle_empty([tuple(e[\"labels\"].values()) for e in most_likely])\n",
    "    trips[\"mli_confidence\"] = handle_empty(confidences)\n",
    "    trips[\"correct\"] = handle_empty(trips[\"all_user_labels\"] == trips[\"most_likely_inference\"])\n",
    "    trips[\"mismatches\"] = handle_empty(trips[[\"all_user_labels_dict\", \"most_likely_inference_dict\"]].apply(dict_diff, axis=\"columns\"))\n",
    "    trips.sort_values(\"mli_confidence\", ascending=False, inplace=True)\n",
    "\n",
    "# Returns all the trips that either have confidence below 1 or are not correctly inferred\n",
    "def get_uncertain(trips):\n",
    "    return trips[(trips[\"mli_confidence\"] < 1) | (~trips[\"correct\"])]\n",
    "\n",
    "# Returns all the trips for which there exists an inference\n",
    "def get_predicted(trips):\n",
    "    return trips[trips[\"most_likely_inference\"] != ()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8315b0",
   "metadata": {},
   "source": [
    "## Explore individual user's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512e9b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_trips = expanded_trip_df_map[target_user].copy()\n",
    "process_trips(user_trips)\n",
    "print(\"Not shown: any trips that the user has not labeled\")\n",
    "\n",
    "uncertain_trips = get_uncertain(user_trips)\n",
    "print(f\"Not shown: {user_trips.shape[0]-uncertain_trips.shape[0]} correctly inferred trips with mli_confidence=1\")\n",
    "\n",
    "predicted_uncertain = get_predicted(uncertain_trips)\n",
    "print(f\"Not shown: {uncertain_trips.shape[0]-predicted_uncertain.shape[0]} trips with no inference\")\n",
    "        \n",
    "display.display(predicted_uncertain[[\"all_user_labels\", \"most_likely_inference\", \"mli_confidence\", \"correct\", \"mismatches\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d44135e",
   "metadata": {},
   "source": [
    "What are the probabilities represented in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d220d699",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_p = user_trips['mli_confidence'].unique()\n",
    "print(f\"{len(unique_p)} unique probabilities:\")\n",
    "print(\"p-value: number of trips\")\n",
    "for p in unique_p:\n",
    "    print(f\"{p:.3f}: {user_trips[user_trips['mli_confidence'] == p].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91755e0d",
   "metadata": {},
   "source": [
    "Comparing stated confidence to actual chance of being correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9620ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"stated p: fraction correct\")\n",
    "for p in unique_p:\n",
    "    n = user_trips[user_trips['mli_confidence'] == p].shape[0]\n",
    "    n_correct = user_trips[(user_trips['mli_confidence'] == p) & (user_trips['correct'])].shape[0]\n",
    "    print(f\"{p:.3f}: {(n_correct/n):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d5e0ad",
   "metadata": {},
   "source": [
    "Presumably the reason for such a close correspondence here is because we trained on this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1d3f02",
   "metadata": {},
   "source": [
    "How about if we break down the label tuples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d1fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"p: number of trips with 0, 1, 2, 3 label mismatches between actual and predicted\")\n",
    "for p in unique_p:\n",
    "    p_trips = user_trips[user_trips['mli_confidence'] == p]\n",
    "    counts = {diffs: p_trips[p_trips['mismatches'] == diffs].shape[0] for diffs in range(0, 4)}\n",
    "    print(f\"{p:.3f}: {list(counts.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debae4a6",
   "metadata": {},
   "source": [
    "Besides emphasizing that we should prioritize reducing the share of trips with no inference over improving the accuracy of inferences, where do we go from here?\n",
    " * We should see what the probability distribution is for unlabeled trips. We won't be able to compare with ground truth, but that way we can see what the probability distribution _actually_ is without it being influenced by training data\n",
    " * We should expand to all users -- this user might not have enough unlabeled trips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2722d91d",
   "metadata": {},
   "source": [
    "## Explore aggregate data\n",
    "Strategies guiding our methodology are:\n",
    "   * Split things up by fully labeled, fully unlabeled, partially labeled\n",
    "   * Calculate probability distribution for each user\n",
    "   * Calculate probability distribution across all users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef2d88e",
   "metadata": {},
   "source": [
    "### More processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcc3e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_non_none(l):\n",
    "    n = 0\n",
    "    for e in l:\n",
    "        if e is not None: n += 1\n",
    "    return n\n",
    "def get_fully_labeled(trips):\n",
    "    return trips[trips[\"all_user_labels\"].apply(count_non_none) == len(LABEL_NAMES)]\n",
    "def get_fully_unlabeled(trips):\n",
    "    return trips[trips[\"all_user_labels\"].apply(count_non_none) == 0]\n",
    "def get_partially_labeled(trips):\n",
    "    lens = trips[\"all_user_labels\"].apply(count_non_none)\n",
    "    return trips[(0 < lens) & (lens < len(LABEL_NAMES))]\n",
    "def prob_dist(trips):\n",
    "    dist = {}\n",
    "    unique_p = trips['mli_confidence'].unique()\n",
    "    unique_p.sort()\n",
    "    unique_p = unique_p[::-1]  # Dictionaries are ordered! And we want ours to be sorted descending.\n",
    "    for p in unique_p: dist[p] = trips[trips['mli_confidence'] == p].shape[0]\n",
    "    return dist\n",
    "def pretty_print_dict(d):\n",
    "    denom = sum(d.values())\n",
    "    print(\"{\")\n",
    "    for k in d:\n",
    "        print(f\"  {k:4.3f}: {d[k]:<4} ({d[k]/denom:.2%})\")\n",
    "    print(\"}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb46d7bf",
   "metadata": {},
   "source": [
    "### Split into fully labeled, fully unlabeled, partially labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269045a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trips_dict, user_labeled, user_unlabeled, user_partial = {}, {}, {}, {}\n",
    "for user in all_users:\n",
    "    these_trips = confirmed_trip_df_map[user].copy()\n",
    "    process_trips(these_trips)\n",
    "    all_trips_dict[user] = these_trips\n",
    "    user_labeled[user] = get_fully_labeled(these_trips)\n",
    "    user_unlabeled[user] = get_fully_unlabeled(these_trips)\n",
    "    user_partial[user] = get_partially_labeled(these_trips)\n",
    "\n",
    "# Yes, we're splitting up into fully labeled, fully unlabeled, partially labeled twice. Can be optimized if necessary.\n",
    "all_trips = pd.concat(all_trips_dict.values())  # This is also somewhat slow and not strictly necessary -- circumvent if necessary\n",
    "all_labeled = get_fully_labeled(all_trips)\n",
    "all_unlabeled = get_fully_unlabeled(all_trips)\n",
    "all_partial = get_partially_labeled(all_trips)\n",
    "\n",
    "print(all_trips.shape)\n",
    "print(all_labeled.shape)\n",
    "print(all_unlabeled.shape)\n",
    "print(all_partial.shape)\n",
    "assert all_labeled.shape[0]+all_unlabeled.shape[0]+all_partial.shape[0] == all_trips.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f042f8d",
   "metadata": {},
   "source": [
    "### Calculate and display probability distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1332d3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_labeled_dist, user_unlabeled_dist, user_partial_dist = [], [], []\n",
    "for user in all_users:\n",
    "    user_labeled_dist.append(prob_dist(user_labeled[user]))\n",
    "    user_unlabeled_dist.append(prob_dist(user_unlabeled[user]))\n",
    "    user_partial_dist.append(prob_dist(user_partial[user]))\n",
    "all_labeled_dist = prob_dist(all_labeled)\n",
    "all_unlabeled_dist = prob_dist(all_unlabeled)\n",
    "all_partial_dist = prob_dist(all_partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc71263",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Not shown: {all_partial.shape[0]} partially labeled trips\")\n",
    "print()\n",
    "\n",
    "print(\"Probability distribution of all fully labeled:\")\n",
    "print(\"Probability: number of trips (percentage of trips)\")\n",
    "pretty_print_dict(all_labeled_dist)\n",
    "print()\n",
    "\n",
    "print(\"Probability distribution of all fully unlabeled:\")\n",
    "print(\"Probability: number of trips (percentage of trips)\")\n",
    "pretty_print_dict(all_unlabeled_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3914e7",
   "metadata": {},
   "source": [
    "Okay, that's useful data. Let's graph it.\n",
    "\n",
    "### Probability distribution graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef5d932",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def bar(labels, a, b, title, figsize):\n",
    "    x = np.arange(len(labels))\n",
    "    y_a = [a[k] if k in a else 0 for k in labels]\n",
    "    y_b = [b[k] if k in b else 0 for k in labels]\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=figsize)\n",
    "    width = 0.4\n",
    "    bars_a = ax.bar(x-width/2, y_a, width, label=\"Fully labeled\")\n",
    "    bars_b = ax.bar(x+width/2, y_b, width, label=\"Fully unlabeled\")\n",
    "\n",
    "    ax.set_ylabel(\"Number of trips\")\n",
    "    ax.set_title(\"Probability distribution of most-likely inferences\"+title)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f\"{n:.2f}\" for n in labels])\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "print(f\"Not shown: {all_partial.shape[0]} partially labeled trips\")\n",
    "labels = (set(all_labeled_dist.keys()) | set(all_unlabeled_dist.keys()))\n",
    "bar(sorted(labels), all_labeled_dist, all_unlabeled_dist, \", full range\", (20,10))\n",
    "bar(sorted(labels - {0.0, 1.0}), all_labeled_dist, all_unlabeled_dist, \" excluding 0 and 1\", (20,10))\n",
    "bar([0.0, 1.0], all_labeled_dist, all_unlabeled_dist, \" only 0 and 1\", (4,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5443b56b",
   "metadata": {},
   "source": [
    "From the graphs, we see that a significant fraction of the unlabeled trips have no inference at all, more so than for labeled trips. There are also more labeled trips with 100% certainty than unlabeled. However, aside from these endpoints, the trend is reversed â€” unlabeled trips tend to cluster towards the middle and upper end of the probability spectrum, whereas labeled trips are more evenly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8629f173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
