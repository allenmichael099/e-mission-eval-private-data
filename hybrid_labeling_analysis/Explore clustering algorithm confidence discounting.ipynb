{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "324ae94e",
   "metadata": {},
   "source": [
    "# Explore clustering algorithm confidence discounting\n",
    "The proposed clustering algorithm confidence discounting algorithm (https://github.com/e-mission/e-mission-docs/issues/663#issuecomment-898994131) has several parameters that may be tuned. This is to explore what they should be set to and whether the algorithm works well overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f855563b",
   "metadata": {},
   "source": [
    "For now, I will not do the full testing, which would consist of a train/test split, running the clustering on only the training data, then comparing the calculated p-values to how well each cluster actually does at predicting test trips."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa730746",
   "metadata": {},
   "source": [
    "First, let's get some users. We select only users who have at least 30 confirmed trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72e9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copypasted from Explore stage before vs after; TODO refactor into a module\n",
    "import emission.storage.timeseries.abstract_timeseries as esta\n",
    "\n",
    "EXCLUDE_UUIDS = [UUID(s) for s in input(\"Enter UUIDs to exclude, separated by spaces: \").split(\" \") if len(s) > 0]\n",
    "REQUIRED_TRIPS_TOTAL = 30\n",
    "\n",
    "def filter_update(new, old, reason):\n",
    "    print(f\"Excluded {len(old)-len(new)} users, left with {len(new)}: {reason}\")\n",
    "\n",
    "all_users = esta.TimeSeries.get_uuid_list()\n",
    "confirmed_trip_df_map = {}\n",
    "print(f\"Working with {len(all_users)} initial users\")\n",
    "\n",
    "filter0_users = [u for u in all_users if u not in EXCLUDE_UUIDS]  # Users that we don't explicitly exclude\n",
    "filter_update(filter0_users, all_users, \"presence on exclusion list\")\n",
    "\n",
    "filter1_users = []  # Users with enough total trips\n",
    "for u in filter0_users:\n",
    "    ts = esta.TimeSeries.get_time_series(u)\n",
    "    ct_df = ts.get_data_df(\"analysis/confirmed_trip\")\n",
    "    confirmed_trip_df_map[u] = ct_df\n",
    "    if ct_df.shape[0] >= REQUIRED_TRIPS_TOTAL: filter1_users.append(u)\n",
    "filter_update(filter1_users, filter0_users, \"not enough total trips\")\n",
    "\n",
    "filtered_users = filter1_users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2e3280",
   "metadata": {},
   "source": [
    "Now let's get all the cleaned trips for those users and figure out what the naïve predictions would be. Note that this requires the model files to be copied into the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046cf7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emission.storage.decorations.analysis_timeseries_queries as esda\n",
    "import emission.analysis.classification.inference.labels.inferrers as eacili\n",
    "import arrow\n",
    "import emission.storage.timeseries.timequery as estt\n",
    "import uuid\n",
    "import emission.analysis.modelling.tour_model.data_preprocessing as preprocess\n",
    "import emission.analysis.modelling.tour_model_first_only.load_predict as lp\n",
    "\n",
    "EMPTY_INFERENCE = {\"labels\": {}, \"p\": 0.0}\n",
    "def mli(labels):  # Most likely inference\n",
    "    return max([e for e in labels], key = lambda e : e[\"p\"]) if len(labels) > 0 else EMPTY_INFERENCE\n",
    "\n",
    "cleaned_trips = []\n",
    "findings = []\n",
    "naive_ps = {0.0, 1.0}\n",
    "naive_counts = {}\n",
    "for u in filtered_users:\n",
    "    tq = estt.TimeQuery(\"data.end_ts\", arrow.get(\"2010-01-01\").timestamp, arrow.now().timestamp)\n",
    "    cleaned_trips += esda.get_entries(esda.CLEANED_TRIP_KEY, u, time_query=tq)\n",
    "for trip in cleaned_trips:\n",
    "    finding = {}\n",
    "    finding[\"trip\"] = trip\n",
    "    finding[\"naive_prediction\"] = eacili.predict_two_stage_bin_cluster(trip)\n",
    "    finding[\"naive_mli_p\"] = mli(finding[\"naive_prediction\"])[\"p\"]\n",
    "    naive_ps.add(finding[\"naive_mli_p\"])\n",
    "    if finding[\"naive_mli_p\"] not in naive_counts: naive_counts[finding[\"naive_mli_p\"]] = 0\n",
    "    naive_counts[finding[\"naive_mli_p\"]] += 1\n",
    "    findings.append(finding)\n",
    "    \n",
    "print(len(cleaned_trips))\n",
    "print(len(findings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b578d94",
   "metadata": {},
   "source": [
    "Now let's compute discounted predictions and test out our graphing functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8789325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The discount data is time-consuming to calculate, so we cache it as a constant tuple: data dict\n",
    "discount_cache = {}  # As long as we specify constant tuples as literals, we shouldn't have to deal with floating-point error in matching to the cache\n",
    "\n",
    "discounted_ps = {0.0, 1.0}\n",
    "discounted_counts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c996d64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_discounting_full(max_confidence=None, first_confidence=None, confidence_multiplier=None):\n",
    "    global discounted_ps, discounted_counts\n",
    "    if (max_confidence, first_confidence, confidence_multiplier) in discount_cache:\n",
    "        discounted_ps, discounted_counts = discount_cache[(max_confidence, first_confidence, confidence_multiplier)]\n",
    "        return\n",
    "    \n",
    "    discounted_ps = {0.0, 1.0}\n",
    "    discounted_counts = {}\n",
    "    for finding in findings:\n",
    "        finding[\"discounted_prediction\"] = eacili.predict_cluster_confidence_discounting(finding[\"trip\"], max_confidence, first_confidence, confidence_multiplier)\n",
    "        finding[\"discounted_mli_p\"] = mli(finding[\"discounted_prediction\"])[\"p\"]\n",
    "        discounted_ps.add(finding[\"discounted_mli_p\"])\n",
    "        if finding[\"discounted_mli_p\"] not in discounted_counts: discounted_counts[finding[\"discounted_mli_p\"]] = 0\n",
    "        discounted_counts[finding[\"discounted_mli_p\"]] += 1\n",
    "    discount_cache[(max_confidence, first_confidence, confidence_multiplier)] = (discounted_ps, discounted_counts)\n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "def bar(labels, a, b, title, figsize):\n",
    "    x = np.arange(len(labels))\n",
    "    y_a = [a[k] if k in a else 0 for k in labels]\n",
    "    y_b = [b[k] if k in b else 0 for k in labels]\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=figsize)\n",
    "    width = 0.4\n",
    "    bars_a = ax.bar(x-width/2, y_a, width, label=\"Naïve\")\n",
    "    bars_b = ax.bar(x+width/2, y_b, width, label=\"Discounted\")\n",
    "\n",
    "    ax.set_ylabel(\"Number of trips\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f\"{n:.2f}\" for n in labels])\n",
    "    ax.legend()\n",
    "    \n",
    "    for i,l in enumerate(ax.xaxis.get_ticklabels()):\n",
    "        if i < 6 or i >= len(labels)-6: l.set_rotation(90)\n",
    "        elif i % 4 != 0: l.set_visible(False)  # Hide labels that don't fit\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def expand_dict(src, dest):\n",
    "    for k in src: dest += [float(k)]*int(src[k])\n",
    "    \n",
    "def box(a, b, title, figsize, first_confidence):\n",
    "    data = [[] for i in range(4)]\n",
    "    labels = [\"Naïve\", \"Discounted\", \"Naïve no 0\", \"Discounted no 0\", \"Naïve no 0, 1\", \"Discounted no 0, B\"]\n",
    "    expand_dict(a, data[0])\n",
    "    expand_dict(b, data[1])\n",
    "    a_no_0 = a.copy()\n",
    "    a_no_0[0] = 0\n",
    "    b_no_0 = b.copy()\n",
    "    b_no_0[0] = 0\n",
    "    expand_dict(a_no_0, data[2])\n",
    "    expand_dict(b_no_0, data[3])\n",
    "    \n",
    "    fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticklabels(labels)\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\") # https://github.com/matplotlib/matplotlib/issues/16353\n",
    "    ax.boxplot(data)\n",
    "    warnings.resetwarnings()\n",
    "    \n",
    "def viz_discounting(max_confidence, first_confidence, confidence_multiplier, bar_figsize=(20,10), box_figsize=(10,5), title_add=\"\"):\n",
    "    compute_discounting_full(max_confidence, first_confidence, confidence_multiplier)\n",
    "    print(f\"Not shown: {naive_counts[0.0]}, {discounted_counts[0.0]} trips with confidence 0\")\n",
    "    labels = list((naive_ps | discounted_ps) - {0.0})\n",
    "    labels.sort()\n",
    "    title = f\"A={1-max_confidence:.2f}, B={first_confidence:.2f}, C={confidence_multiplier:.2f}\"+title_add\n",
    "    bar(labels, naive_counts, discounted_counts, title, bar_figsize)\n",
    "    box(naive_counts, discounted_counts, title, box_figsize, first_confidence)\n",
    "    \n",
    "viz_discounting(0.99, 0.75, 0.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e38c3aa",
   "metadata": {},
   "source": [
    "And now let's use the graphs to test out a bunch of scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9485d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = {\n",
    "    \"default\": (0.99, 0.75, 0.25),\n",
    "    \"no_a\": (1.00, 0.75, 0.25),\n",
    "    \"high_a\": (0.95, 0.75, 0.25),\n",
    "    \"higher_a\": (0.90, 0.75, 0.25),\n",
    "    \"low_b\": (0.99, 0.6, 0.25),\n",
    "    \"lower_b\": (0.99, 0.3, 0.25),\n",
    "    \"low_c\": (0.99, 0.5, 0.10),\n",
    "    \"low_b_and_c\": (0.99, 0.6, 0.10)\n",
    "}\n",
    "\n",
    "for scenario in scenarios:\n",
    "    viz_discounting(*scenarios[scenario], title_add=f\" ({scenario})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d84f590",
   "metadata": {},
   "source": [
    "A quick check on what keys we have to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf05edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_cache.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7535f4",
   "metadata": {},
   "source": [
    "Now let's make some better boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1197e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_cache(scenario, remove_0=False):\n",
    "    compute_discounting_full(*scenario)\n",
    "    dest = []\n",
    "    d = discounted_counts.copy()\n",
    "    if remove_0: d[0] = 0\n",
    "    expand_dict(d, dest)\n",
    "    return dest\n",
    "\n",
    "def box_sidebyside(scenarios, remove_0=True):\n",
    "    labels = [\"naïve\\n(no discounting)\"]+list(scenarios.keys())\n",
    "    for i,label in enumerate(labels):\n",
    "        if i == 0: continue\n",
    "        s = scenarios[label]\n",
    "        labels[i] += f\"\\n({s[0]:.2f}, {s[1]:.2f}, {s[2]:.2f})\"\n",
    "        naive_counts_no_0 = naive_counts.copy()\n",
    "        if remove_0: naive_counts_no_0[0] = 0\n",
    "        naive_no_0 = []\n",
    "        expand_dict(naive_counts_no_0, naive_no_0)\n",
    "    data = [naive_no_0]+[expand_cache(s, remove_0=remove_0) for s in scenarios.values()]\n",
    "    \n",
    "    fig,ax = plt.subplots(figsize=(15,5))\n",
    "    ax.set_title(f\"Side-by-side scenario comparison, most likely inference, {'NOT ' if not remove_0 else ''}removing 0\")\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_ylim([-0.05, 1.05])\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\") # https://github.com/matplotlib/matplotlib/issues/16353\n",
    "    ax.boxplot(data)\n",
    "    ax.grid(axis=\"y\")\n",
    "    warnings.resetwarnings()\n",
    "    \n",
    "    \n",
    "box_sidebyside(scenarios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fe48e7",
   "metadata": {},
   "source": [
    "And let's try some more scenarios altering just B and C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0132a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios2 = {\n",
    "    \"default\": (0.99, 0.75, 0.25),\n",
    "    \"low_b\": (0.99, 0.6, 0.25),\n",
    "    \"low_c\": (0.99, 0.5, 0.10),\n",
    "    \"low_b_and_c\": (0.99, 0.6, 0.10),\n",
    "    \"high_b\": (0.99, 0.9, 0.25),\n",
    "    \"high_c\": (0.99, 0.75, 0.33),\n",
    "    \"high_b_and_c\": (0.99, 0.9, 0.33)\n",
    "}\n",
    "box_sidebyside(scenarios2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2045730",
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in scenarios2:\n",
    "    print(scenario)\n",
    "    print([f\"{eacili.n_to_confidence_coeff(n, *scenarios2[scenario]):.3f}\" for n in range(1,11)])\n",
    "    print()                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b897b023",
   "metadata": {},
   "source": [
    "Let's try to get a B and a C by working backwards. We'll say that under relaxed mode, we need\n",
    " 1. 1 occurrence of a common trip before it shows up as yellow\n",
    " 2. 4 occurrences of a common trip before the user doesn't need to interact with it at all\n",
    " 3. If the first occurrence of a common trip has label tuple X, we need 1 occurrence with label tuple Y before we show label tuple Y as yellow\n",
    " 4. If the first occurrence of a common trip has label tuple X, we need 10 occurrences with label tuple Y before we predict label tuple Y and don't require any user interaction\n",
    "\n",
    "and under intensive mode we need\n",
    " 1. 1 occurrence of a common trip before it shows up as yellow\n",
    " 2. Infinite occurrences of a common trip before the user doesn't need to interact with it at all (in intensive mode, we want to capture things like the user drove alone for years but now they're carpooling)\n",
    " 3. If the first occurrence of a common trip has label tuple X, we need 2 occurrences with label tuple Y before we show label tuple Y as yellow\n",
    " 4. If the first occurrence of a common trip has label tuple X, we need infinite occurrences with label tuple Y before we predict label tuple Y and don't require any user interaction\n",
    "\n",
    "From this we deduce:\n",
    " * Relaxed 3 implies that our intensive low confidence threshold should be roughly between 0.00 and 0.50\n",
    " * Relaxed 4 implies that our relaxed high confidence threshold should be roughly between 0.90 and 0.91\n",
    " * Intensive 3 implies that our intensive low confidence threshold should be roughly between 0.50 and 0.66\n",
    " * Intensive 4 implies that our intensive high confidence threshold should be roughly between A and 1\n",
    "\n",
    "Let us set:\n",
    " * Relaxed low confidence threshold: 0.40\n",
    " * Relaxed high confidence threshold: 0.90\n",
    " * Intensive low confidence threshold: 0.60\n",
    " * Intensive high confidence threshold: 0.99 (or whatever A is if we change it)\n",
    "\n",
    "Now that we have that, we can deduce some more:\n",
    " * Relaxed 1 implies that B is greater than 0.40\n",
    " * Relaxed 2 implies that the discount for `n=4` should be between 0.90 and 1.00 and the discount for `n=3` should be less than or equal to 0.90\n",
    " * Intensive 1 implies that B is greater than 0.60\n",
    "\n",
    "If we fix `B=0.85`, what do we need C to be to fulfill Relaxed 2 (and the rest of the criteria)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee90b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_c(A, B, n_range, search_range):\n",
    "    print(\"Searching for C:\")\n",
    "    for C in search_range:\n",
    "        print(f\"({1-A:.2f}, {B:.2f}, {C:.2f})\")\n",
    "        print([f\"{eacili.n_to_confidence_coeff(n, 1-A, B, C):.3f}\" for n in n_range])\n",
    "        print()\n",
    "search_for_c(0.01, 0.85, [3,4], np.arange(0.10, 0.40, 0.05))\n",
    "search_for_c(0.01, 0.85, [3,4], np.arange(0.12, 0.20, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f928e70",
   "metadata": {},
   "source": [
    "So C can be 0.14 through 0.20. That's on the low side. Lowering B would let us raise C. How much? If we fix `B=0.75`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed4b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_for_c(0.01, 0.75, [3,4], np.arange(0.10, 0.40, 0.05))\n",
    "search_for_c(0.01, 0.75, [3,4], np.arange(0.25, 0.40, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cecfd20",
   "metadata": {},
   "source": [
    "So now C can be in the range 0.29 through 0.38. What about `B=0.80`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e5259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_for_c(0.01, 0.80, [3,4], np.arange(0.10, 0.40, 0.05))\n",
    "search_for_c(0.01, 0.80, [3,4], np.arange(0.20, 0.35, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adbc9e7",
   "metadata": {},
   "source": [
    "Here it's 0.23 through 0.31."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec5673c",
   "metadata": {},
   "source": [
    "Let us preliminarily propose `A=0.01, B=0.80, C=0.30` and verify that it meets the criteria above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d0e21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print({n: f\"{eacili.n_to_confidence_coeff(n, 0.99, 0.80, 0.30):.3f}\" for n in range(1,16)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461e5405",
   "metadata": {},
   "source": [
    "Everything checks out, except we require 11 instead of 10 for Relaxed 4. We could remedy this either by changing Relaxed 4 to 11 or by changing relaxed high confidence threshold to 0.89. I propose the latter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f43a30",
   "metadata": {},
   "source": [
    "### Final proposal\n",
    "Thus, my final proposal is:\n",
    "\n",
    "Discounting constants:\n",
    " * `A=0.01`, `B=0.80`, `C=0.30`\n",
    " \n",
    "Configuration values:\n",
    " * Relaxed mode: low confidence threshold: `0.40`; high confidence threshold: `0.89`\n",
    " * Intensive mode: low confidence threshold: `0.60`; high confidence threshold: `0.99`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3080b8f",
   "metadata": {},
   "source": [
    "For completeness, here's a box plot of that versus some past scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13165e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios3 = {\n",
    "    \"default\": (0.99, 0.75, 0.25),\n",
    "    \"low_b_and_c\": (0.99, 0.6, 0.10),\n",
    "    \"high_b_and_c\": (0.99, 0.9, 0.33),\n",
    "    \"final_proposal\": (0.99, 0.80, 0.30)\n",
    "}\n",
    "box_sidebyside(scenarios3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31948f62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
