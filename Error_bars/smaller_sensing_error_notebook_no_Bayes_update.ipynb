{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from uuid import UUID\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/mallen2/alternate_branches/eval-compatible-server/e-mission-server')\n",
    "\n",
    "import emission.storage.timeseries.abstract_timeseries as esta\n",
    "import emission.storage.decorations.trip_queries as esdtq\n",
    "import emission.core.wrapper.user as ecwu\n",
    "\n",
    "import confusion_matrix_handling as cm_handling\n",
    "from confusion_matrix_handling import MODE_MAPPING_DICT\n",
    "import get_EC\n",
    "import helper_functions as hf\n",
    "\n",
    "import sklearn.model_selection as skm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model\n",
    "\n",
    "METERS_TO_MILES = 0.000621371 # 1 meter = 0.000621371 miles\n",
    "ECAR_PROPORTION = 0 #0.01 #~1% of cars on the road are electric.\n",
    "\n",
    "df_EI = pd.read_csv(r'Public_Dashboard/auxiliary_files/energy_intensity.csv') # r stands for raw string, only matters if the path is on Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run \"Store_expanded_labeled_trips.ipynb\" first.\n",
    "%store -r expanded_labeled_trips \n",
    "unit_dist_MCS_df = pd.read_csv(\"unit_distance_MCS.csv\").set_index(\"moment\")\n",
    "energy_dict = cm_handling.get_energy_dict(df_EI)\n",
    "\n",
    "# maybe make this a function?\n",
    "\n",
    "# here I'm referring to car_load_factor: the number that we divide the drove alone energy intensity by\n",
    "# for r = 1, car_load_factor is 4/3.\n",
    "r = 1\n",
    "car_load_factor = (r+1)/(r+0.5)     \n",
    "gas_car_drove_alone_EI = energy_dict[\"Gas Car, drove alone\"]\n",
    "e_car_drove_alone_EI = energy_dict[\"E-car, drove alone\"]\n",
    "# NOTE: MODE_MAPPING_DICT (seen in confusion_matrix_handling.py) is currently mapping 'drove_alone' \n",
    "# (from before the OpenPATH update that distinguished E-car and gas car) to 'Gas Car, drove alone.'\n",
    "# MODE_MAPPING_DICT = {'drove_alone': 'Gas Car, drove alone', ...\n",
    "\n",
    "# Include the chance of electric car in the sensed energy intensity.\n",
    "sensed_car_drove_alone_EI = ECAR_PROPORTION*e_car_drove_alone_EI + (1-ECAR_PROPORTION)*gas_car_drove_alone_EI\n",
    "\n",
    "# Include the chance that a sensed car trip is shared ride.\n",
    "sensed_car_EI = sensed_car_drove_alone_EI/car_load_factor\n",
    "\n",
    "energy_dict.update({\"Car, sensed\": sensed_car_EI})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_labeled_trips = hf.drop_unwanted_trips(expanded_labeled_trips,drop_not_a_trip=False)\n",
    "expanded_labeled_trips = hf.get_primary_modes(expanded_labeled_trips,energy_dict,MODE_MAPPING_DICT)\n",
    "print('Here are the number of labeled trips remaining in each program dataset:')\n",
    "expanded_labeled_trips.program.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the confusion matrices and then the EI moments from those.\n",
    "android_confusion = pd.read_csv(\"android_confusion.csv\").set_index('gt_mode')\n",
    "ios_confusion = pd.read_csv(\"ios_confusion.csv\").set_index('gt_mode')\n",
    "\n",
    "android_confusion = cm_handling.collapse_confusion_matrix(android_confusion, rows_to_collapse={\"Train\": [\"Train\"]}, columns_to_collapse={})\n",
    "ios_confusion = cm_handling.collapse_confusion_matrix(ios_confusion, rows_to_collapse={\"Train\": [\"Train\"]}, columns_to_collapse={})\n",
    "\n",
    "expanded_labeled_trips['distance_miles'] = expanded_labeled_trips.distance*METERS_TO_MILES\n",
    "EI_length_cov = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you forget this step, the error for expected may be different, \n",
    "# since you might be relying on a different saved version of the EI_moments_dataframe\n",
    "android_EI_moments_df = cm_handling.get_conditional_EI_expectation_and_variance(android_confusion,energy_dict)\n",
    "ios_EI_moments_df = cm_handling.get_conditional_EI_expectation_and_variance(ios_confusion,energy_dict)\n",
    "os_EI_moments_map = {'ios': ios_EI_moments_df, 'android': android_EI_moments_df}\n",
    "energy_consumption_df = get_EC.compute_all_EC_values(expanded_labeled_trips,unit_dist_MCS_df,energy_dict,android_EI_moments_df,ios_EI_moments_df, \\\n",
    "    EI_length_cov, print_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_percent_error_map = hf.get_program_percent_error_map(energy_consumption_df)\n",
    "percent_error_df = pd.DataFrame(program_percent_error_map,index=[0])\n",
    "percent_error_markdown = percent_error_df.round(2).to_markdown()\n",
    "print(percent_error_markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using aggregate distances when computing variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell plots the user labeled and expected aggregate energy consumptions on the left and right, respectively.\n",
    "program_n_sd_map_aggregate_distance = hf.plot_estimates_with_sd_by_program(energy_consumption_df,os_EI_moments_map,unit_dist_MCS_df,variance_method=\"aggregate_distance\")\n",
    "print(f\"number of standard deviations from mean: {program_n_sd_map_aggregate_distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the sum of individual variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell plots the user labeled and expected aggregate energy consumptions on the left and right, respectively.\n",
    "# It uses the old method of getting aggregate variance (add up individual variances, no covariance term).\n",
    "program_n_sd_map_individual_trips = hf.plot_estimates_with_sd_by_program(energy_consumption_df,os_EI_moments_map,unit_dist_MCS_df,variance_method=\"independent individual trips\")\n",
    "print(f\"number of standard deviations from mean: {program_n_sd_map_individual_trips}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar chart version!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell plots the user labeled and expected aggregate energy consumptions on the left and right, respectively.\n",
    "hf.plot_aggregate_EC_bar_chart(energy_consumption_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now try with a Bayes update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_probs_prespecified = {\"Gas Car, sensed\": 0.85, \"Pilot ebike\": 0.05}\n",
    "prior_probs = prior_probs_prespecified.copy()\n",
    "n_other_modes = len(android_confusion.index) - len(prior_probs_prespecified)\n",
    "probability_remaining = 1 - sum(prior_probs_prespecified.values())\n",
    "prior_probs.update({x: probability_remaining/n_other_modes for x in android_confusion.index if x not in prior_probs_prespecified.keys()})\n",
    "#prior_probs = {x: 1/len(android_confusion.index) for x in android_confusion.index} # if you want a uniform prior.\n",
    "\n",
    "android_EI_moments_with_Bayes_update_df = cm_handling.get_Bayesian_conditional_EI_expectation_and_variance(android_confusion,energy_dict, prior_probs)\n",
    "ios_EI_moments_with_Bayes_update_df = cm_handling.get_Bayesian_conditional_EI_expectation_and_variance(ios_confusion,energy_dict, prior_probs)\n",
    "os_EI_moments_with_Bayes_update_map = {'ios': ios_EI_moments_with_Bayes_update_df, 'android': android_EI_moments_with_Bayes_update_df}\n",
    "energy_consumption_with_Bayes_update_df = get_EC.compute_all_EC_values(expanded_labeled_trips,unit_dist_MCS_df,energy_dict,\\\n",
    "    android_EI_moments_with_Bayes_update_df,\\\n",
    "    ios_EI_moments_with_Bayes_update_df, \\\n",
    "    EI_length_cov, print_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate distance method\n",
    "# This cell plots the user labeled and expected aggregate energy consumptions on the left and right, respectively. \n",
    "program_n_sd_map = hf.plot_estimates_with_sd_by_program(energy_consumption_with_Bayes_update_df,os_EI_moments_with_Bayes_update_map, unit_dist_MCS_df, variance_method='aggregate_distance')\n",
    "print(f\"number of standard deviations from mean: {program_n_sd_map}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial covariance method\n",
    "program_n_sd_map = hf.plot_estimates_with_sd_by_program(energy_consumption_df,os_EI_moments_map,unit_dist_MCS_df,variance_method=\"aggregate_distance\")\n",
    "print(f\"number of standard deviations from mean: {program_n_sd_map}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the proportions of each mode in mobilitynet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mobilitynet_trips = android_confusion + ios_confusion\n",
    "durations_in_modes = all_mobilitynet_trips.sum(axis=1)\n",
    "mobility_net_mode_proportions = durations_in_modes/all_mobilitynet_trips.sum().sum() #this gives the proportions of each mode in mobilitynet\n",
    "print(mobility_net_mode_proportions.round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility_net_mode_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration that dividing each android confusion column by its column sum is \n",
    "# equivalent to assuming that the data has the same prior mode distribution as the android trips in mobility net\n",
    "android_confusion = pd.read_csv(\"android_confusion.csv\").set_index('gt_mode')#+ ios_confusion\n",
    "\n",
    "durations_in_modes = android_confusion.sum(axis=1)\n",
    "prior_mode_probs = durations_in_modes/all_mobilitynet_trips.sum().sum()\n",
    "\n",
    "p_predicted_given_actual = android_confusion.divide(android_confusion.sum(axis=1), axis='rows')\n",
    "\n",
    "likelihood_times_priors = p_predicted_given_actual.multiply(pd.Series(prior_mode_probs), axis='rows')\n",
    "normalizing_constants = likelihood_times_priors.sum(axis='rows')\n",
    "prob_actual_given_predicted_df = likelihood_times_priors.divide(normalizing_constants, axis='columns').copy()\n",
    "prob_actual_given_predicted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ios_confusion = pd.read_csv(\"ios_confusion.csv\").set_index('gt_mode')\n",
    "android_confusion = pd.read_csv(\"android_confusion.csv\").set_index('gt_mode')#+ ios_confusion\n",
    "\n",
    "all_mobilitynet_trips = android_confusion + ios_confusion\n",
    "durations_in_modes = all_mobilitynet_trips.sum(axis=1)\n",
    "prior_mode_probs = durations_in_modes/all_mobilitynet_trips.sum().sum()\n",
    "\n",
    "p_predicted_given_actual = android_confusion.divide(android_confusion.sum(axis=1), axis='rows')\n",
    "\n",
    "likelihood_times_priors = p_predicted_given_actual.multiply(pd.Series(prior_mode_probs), axis='rows')\n",
    "normalizing_constants = likelihood_times_priors.sum(axis='rows')\n",
    "prob_actual_given_predicted_df = likelihood_times_priors.divide(normalizing_constants, axis='columns').copy()\n",
    "prob_actual_given_predicted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_energy_consumption_by_mode(energy_consumption_df,program_name, main_mode_labels = ['drove_alone','shared_ride','walk','pilot_ebike','bus','bike','train','taxi','free_shuttle']):\n",
    "    df = energy_consumption_df.copy()\n",
    "    program_main_mode_labels = [x for x in main_mode_labels if x in df.mode_confirm.unique()] # 4c doesn't have train before May 2022.\n",
    "\n",
    "    program_main_modes_EC = df.groupby('mode_confirm').sum().loc[program_main_mode_labels]\n",
    "    program_main_modes_EC = program_main_modes_EC[['expected','user_labeled']] # 'predicted',\n",
    "\n",
    "    program_main_modes_EC.plot(kind='barh')\n",
    "    program_percent_error_expected = 100*hf.relative_error(df.expected.sum(),df.user_labeled.sum())\n",
    "    plt.xlabel('Energy consumption (kWH)')\n",
    "    plt.ylabel('user labeled mode')\n",
    "    plt.title(f\"Energy consumption estimates by user labeled mode for {program_name}\\nCustom mode labels not shown\\n(full % error for expected: {program_percent_error_expected:.2f})\")\n",
    "\n",
    "plot_energy_consumption_by_mode(energy_consumption_df,'all CEO + stage', main_mode_labels = ['drove_alone','shared_ride','walk','pilot_ebike','bus','bike','train','taxi','free_shuttle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what percent of all ceo trips are ebike?\n",
    "energy_consumption_df.groupby('mode_confirm').sum()['distance']['pilot_ebike']/energy_consumption_df.distance.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this version of show_bootstrap shows the distribution of errors rather than expected values.\n",
    "def show_bootstrap(df,program,os_EI_moments_map,unit_dist_MCS_df, print_results):\n",
    "    print(program)\n",
    "    NB = 300\n",
    "    df = df.copy()\n",
    "    df = df.set_index(\"_id\")\n",
    "    aggregate_EC_estimates = []\n",
    "    aggregate_EC_actual = []\n",
    "    sd_list = []\n",
    "    for j in range(0,NB):\n",
    "        bootstrap_idx = np.random.choice(df.index,len(df),replace=True)\n",
    "        bootstrap_sample = df.loc[bootstrap_idx]\n",
    "        aggregate_EC_estimates.append(sum(bootstrap_sample.expected))\n",
    "        aggregate_EC_actual.append(sum(bootstrap_sample.user_labeled))\n",
    "        sd_list.append(get_EC.get_totals_and_errors(df, os_EI_moments_map, unit_dist_MCS_df, include_autocovariance=False)['aggregate_sd'])\n",
    "\n",
    "    aggregate_EC_estimates = np.array(aggregate_EC_estimates)\n",
    "    aggregate_EC_actual = np.array(aggregate_EC_actual)\n",
    "    errors = aggregate_EC_estimates - aggregate_EC_actual\n",
    "\n",
    "    totals_and_errors = get_EC.get_totals_and_errors(df, os_EI_moments_map, unit_dist_MCS_df, include_autocovariance=False)\n",
    "    total_expected = totals_and_errors['total_expected']\n",
    "    boot_mean = np.mean(aggregate_EC_estimates)\n",
    "    sd = totals_and_errors[\"aggregate_sd\"]\n",
    "    boot_sd = np.sqrt(np.var(aggregate_EC_estimates))\n",
    "\n",
    "    if print_results == True:\n",
    "        plt.hist(errors)\n",
    "\n",
    "        print(f'our estimate: {total_expected:.2f}\\nTrue value: {totals_and_errors[\"total_user_labeled\"]:.2f}\\nMean of bootstrap estimates: {boot_mean:.2f}')\n",
    "        print(f'our error: {sum(energy_consumption_df.expected - energy_consumption_df.user_labeled):.2f}')\n",
    "\n",
    "        print(f'our 1 sd interval: {total_expected - sd:.2f},{total_expected + sd:.2f}')\n",
    "        print(f'bootstrap 1 sd interval: {boot_mean - boot_sd:.2f},{boot_mean + boot_sd:.2f}')\n",
    "        print(f'bootstrap 2 sd interval: {boot_mean - 2*boot_sd:.2f},{boot_mean + 2*boot_sd:.2f}')\n",
    "\n",
    "    # I want to know: how does the error compare to the standard deviation each time?\n",
    "    return abs(errors)/np.array(sd_list)\n",
    "\n",
    "#show_bootstrap(energy_consumption_df,'all', os_EI_moments_map, unit_dist_MCS_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_errors_over_sd = np.array()\n",
    "for program in energy_consumption_df.program.unique():\n",
    "    error_over_sd = show_bootstrap(energy_consumption_df[energy_consumption_df.program == program],program, os_EI_moments_map, unit_dist_MCS_df, print_results= False)\n",
    "    all_errors_over_sd = np.append(all_errors_over_sd, error_over_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(error_over_sd); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and sd for all user labeled and for all sensed:\n",
    "mean_EC_all_sensing = sum(elt_with_errors_outliers_removed['expected'])\n",
    "mean_EC_all_user_labeled = sum(elt_with_errors_outliers_removed['user_labeled'])\n",
    "\n",
    "sd_sensed = np.sqrt(sum(elt_with_errors_outliers_removed['confusion_var']))\n",
    "sd_users = np.sqrt(sum(elt_with_errors_outliers_removed['user_var']))\n",
    "\n",
    "# Now calculate for various random splits of the data\n",
    "# 10^3 NMC takes 10 seconds on vail to create all 4 splits.\n",
    "proportion_sensed = [0.2,0.4,0.6,0.8]\n",
    "NMC = 100#**2#**3\n",
    "\n",
    "summary_df_map = {}\n",
    "for ps in proportion_sensed:\n",
    "    \n",
    "    mean_EC_agg = []\n",
    "    var_EC_agg = []\n",
    "    error_EC_agg = []\n",
    "    for j in range(0,NMC):\n",
    "        rand_state = np.random.RandomState(1+j)\n",
    "\n",
    "        # Split the labeled trips into a user labeled dataframe and a sensed dataframe\n",
    "        user_labeled,sensed  = skm.train_test_split(elt_with_errors_outliers_removed , \n",
    "                                                    test_size = ps, # sensed\n",
    "                                                    train_size = 1-ps,  # user_labeled\n",
    "                                                    random_state= rand_state)\n",
    "        mean_EC_sensed, var_EC_sensed = sum(sensed['expected']), sum(sensed['confusion_var'])\n",
    "        \n",
    "        mean_EC_user_labeled, var_EC_user_labeled = sum(user_labeled['user_labeled']), sum(user_labeled['user_var'])\n",
    "\n",
    "        # Get the total mean and variance for the current iteration and add it to a list.\n",
    "        current_aggregate_EC = mean_EC_sensed + mean_EC_user_labeled\n",
    "        mean_EC_agg.append(current_aggregate_EC)\n",
    "        var_EC_agg.append(var_EC_sensed + var_EC_user_labeled)\n",
    "        error_EC_agg.append(current_aggregate_EC - mean_EC_all_user_labeled)\n",
    "\n",
    "        sd_EC_agg = np.sqrt(np.array(var_EC_agg))\n",
    "\n",
    "    summary_df_map[ps] = pd.DataFrame({\"mean\": mean_EC_agg, \"sd\": sd_EC_agg, 'error': error_EC_agg})\n",
    " \n",
    "        # prop var sensed\n",
    "        # prop var user labeled\n",
    "average_summaries = {}\n",
    "for ps in proportion_sensed:\n",
    "    average_across_splits_mean = np.mean(summary_df_map[ps][\"mean\"])\n",
    "    average_across_splits_sd = np.mean(summary_df_map[ps][\"sd\"])\n",
    "    average_summaries[ps] = {\"mean\": average_across_splits_mean, \"sd\": average_across_splits_sd}\n",
    "\n",
    "def get_interval(mean,sd):\n",
    "    return [mean -sd, mean,mean + sd]\n",
    "\n",
    "interval_sensed_vail = get_interval(mean_EC_all_sensing,sd_sensed)\n",
    "interval_users_vail = get_interval(mean_EC_all_user_labeled,sd_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on some datasets we can be more certain than others, and we might be less biased. But we don't know which ones that is the case for.\n",
    "# how does spatial cov do on the largely ebike dataset? # how does spatial cov do with my uniform prior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate variance with sections or calculate mean with primary mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_aggregate_variance_with_total_distance_from_sections(df, os_EI_moments_map, unit_dist_MCS_df):\n",
    "    '''\n",
    "    Finds total distances in each predicted mode and uses those totals in the final aggregate variance calculation.\n",
    "\n",
    "    df: trips dataframe with a primary_mode column.\n",
    "    os_EI_moments_map: dictionary by operating system of energy intensity moments dataframes, which store mean and variance of energy intensity\n",
    "        for each predicted mode.\n",
    "    unit_dist_MCS_df: mean and variance estimates for unit distance trips.\n",
    "\n",
    "    Returns the aggregate variance (var_total)\n",
    "    '''\n",
    "    var_total = 0\n",
    "\n",
    "    for os in df.os.unique():\n",
    "        single_os_trips = df[df.os == os].copy()\n",
    "\n",
    "        # Get OS specific trip length info.\n",
    "        mean_for_unit_L = unit_dist_MCS_df[os][\"mean\"]\n",
    "        var_for_unit_L = unit_dist_MCS_df[os][\"var\"]\n",
    "\n",
    "        sensed_mode_distance_map = {}\n",
    "        for _,ct in energy_consumption_df.iterrows():\n",
    "            sections_lengths = np.array(ct[\"section_distances\"])*METERS_TO_MILES \n",
    "            for i, mode in enumerate(ct[\"section_modes\"]):\n",
    "                if mode not in sensed_mode_distance_map.keys():\n",
    "                    sensed_mode_distance_map[mode] = 0\n",
    "                # Add to the total distance traveled in this mode.\n",
    "                sensed_mode_distance_map[mode] += sections_lengths[i]\n",
    "                \n",
    "        for mode in sensed_mode_distance_map.keys():\n",
    "            mean_L = sensed_mode_distance_map[mode]*mean_for_unit_L\n",
    "            var_L = sensed_mode_distance_map[mode]**2 * var_for_unit_L  \n",
    "            mode = 'train' if mode == 'air_or_hsr' else mode\n",
    "\n",
    "            mean_EI = os_EI_moments_map[os][\"mean(EI)\"][mode] \n",
    "            var_EI = os_EI_moments_map[os][\"variance(EI)\"][mode] \n",
    "\n",
    "            var_total += var_EI*mean_L**2 + var_L*mean_EI**2 #+ 2*cov(EI,L)*mean_EI*mean_L  if including covariance\n",
    "\n",
    "    return var_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_based_on_sections = compute_aggregate_variance_with_total_distance_from_sections(expanded_labeled_trips, os_EI_moments_map, unit_dist_MCS_df)\n",
    "\n",
    "# the version that I've been using takes the total distance in miles for the trip and groups by primary mode.\n",
    "var_based_on_primary_modes = get_EC.compute_aggregate_variance(expanded_labeled_trips, os_EI_moments_map, unit_dist_MCS_df)\n",
    "np.sqrt(var_based_on_sections), np.sqrt(var_based_on_primary_modes) # bigger difference than I expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expected_EC_for_one_trip(ct, unit_dist_MCS_df,android_EI_moments, ios_EI_moments, EI_length_covariance):\n",
    "    '''\n",
    "    Finds the expected mean energy consumption and variance for a single trip.\n",
    "    The variance is calculated with variance propagation of the energy intensity variance and the trip length variance.\n",
    "\n",
    "    ct:                     confirmed trip. A row of a labeled trips dataframe.\n",
    "    unit_dist_MCS_df:       dataframe containing the mean and variance of trip length for a 1 unit long trip, for both operating systems.\n",
    "    energy_dict:            dictionary by mode of energy intensities in kWH.\n",
    "    android_EI_moments:     dataframe of energy intensity mean and variance for each mode sensed with android.\n",
    "    ios_EI_moments:         dataframe of energy intensity mean and variance for each mode sensed with ios.\n",
    "\n",
    "    EI_length_covariance:   (assumed to be 0). covariance between trip energy intensity and trip length.\n",
    "        To use this, we would need to either find a value based on past user labels or estimate this with sensed energy consumption.\n",
    "        I'm not sure whether this should be different for different sensed modes (ie, use a covariance conditional on sensed mode), \n",
    "        since knowing the sensed mode tells us more information about the energy consumption than if we had no knowledge.\n",
    "\n",
    "        With all CEO + stage user labels, I estimated EI_length covariance as 1.29.\n",
    "        You might also need to add the covariance to each trip energy consumption estimate since E[XY] = E[X]E[Y] + cov(X,Y), \n",
    "        but this could drastically overestimate energy consumption if we use a covariance of 1.2 for every trip, \n",
    "        which would be similar to assigning every trip to drove alone or a higher intensity mode.\n",
    "    \n",
    "    Returns the expected energy consumption mean and variance as a tuple of floats: trip_mean_EC, trip_var_EC.\n",
    "    '''\n",
    "    #Initialize trip energy consumption\n",
    "    trip_mean_EC = 0\n",
    "    trip_var_EC = 0\n",
    "\n",
    "    # Get operating system\n",
    "    os = ct['os']\n",
    "\n",
    "    # Get OS specific trip length info.\n",
    "    mean_for_unit_L = unit_dist_MCS_df[os][\"mean\"]\n",
    "    var_for_unit_L = unit_dist_MCS_df[os][\"var\"]\n",
    "\n",
    "    # Get trip mode info.\n",
    "    # Get segments for the trip.\n",
    "    n_sections = len(ct[\"section_modes\"])\n",
    "    section_modes = ct[\"section_modes\"]\n",
    "    sections_lengths = np.array(ct[\"section_distances\"])*METERS_TO_MILES   # 1 meter = 0.000621371 miles\n",
    "\n",
    "    mean_L = sections_lengths*mean_for_unit_L\n",
    "    var_L = sections_lengths**2 * var_for_unit_L  \n",
    "        \n",
    "    for current_section in range(0,n_sections):\n",
    "        # EI mean and variance.\n",
    "        # Perhaps it would be better to keep the moments in the same file?\n",
    "\n",
    "        # Later: switch to a map style function.\n",
    "        mean_EI, var_EI = get_EI_moments_for_trip(section_modes[current_section],os,android_EI_moments,ios_EI_moments)\n",
    "\n",
    "        # Propagate variance for the trip\n",
    "        mean_EC = mean_L[current_section]*mean_EI\n",
    "        var_EC = var_EI*mean_L[current_section]**2 + var_L[current_section]*mean_EI**2 + 2*EI_length_covariance*mean_EI*mean_L[current_section]\n",
    "\n",
    "        # Add to total - follows from assumed independence of section errors.  # Might want to consider dependence between sections.\n",
    "        trip_mean_EC += mean_EC\n",
    "        trip_var_EC += var_EC\n",
    "\n",
    "    return trip_mean_EC, trip_var_EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expected_based_on_primary_mode_for_one_trip(ct, unit_dist_MCS_df, android_EI_moments, ios_EI_moments):\n",
    "\n",
    "    # Get operating system\n",
    "    os = ct['os']\n",
    "\n",
    "    # Get OS specific trip length info.\n",
    "    mean_for_unit_L = unit_dist_MCS_df[os][\"mean\"]\n",
    "    var_for_unit_L = unit_dist_MCS_df[os][\"var\"]\n",
    "\n",
    "    # Get primary mode\n",
    "    longest_section_distance = max(ct[\"section_distances\"])*METERS_TO_MILES\n",
    "    primary_mode = ct[\"section_modes\"][ct[\"section_distances\"]==longest_section_distance]\n",
    "\n",
    "    # in case there are ever tied longest sections.\n",
    "    # pick the most energy intensive mode.\n",
    "    if isinstance(primary_mode,list): \n",
    "        mini_energy_dict = {x:energy_dict[MODE_MAPPING_DICT[x]] for x in primary_mode}\n",
    "        primary_mode = max(mini_energy_dict, key=mini_energy_dict.get)\n",
    "        print(f\"found a tie for longest section. Choosing {primary_mode}\")\n",
    "\n",
    "    mean_EI, var_EI = get_EC.get_EI_moments_for_trip(primary_mode,os,android_EI_moments,ios_EI_moments)\n",
    "\n",
    "    # use longest section distance or use trip distance?\n",
    "    # mean_EC = longest_section_distance*mean_for_unit_L*mean_EI\n",
    "    mean_EC = ct[\"distance_miles\"]*mean_for_unit_L*mean_EI\n",
    "\n",
    "    return mean_EC\n",
    "    \n",
    "def compute_all_EC_values_from_primary_mode(df, unit_dist_MCS_df,energy_dict, android_EI_moments_df,ios_EI_moments_df):\n",
    "\n",
    "    print(\"Computing energy consumption for each trip.\")\n",
    "    expected = []\n",
    "\n",
    "    for _,ct in df.iterrows():\n",
    "        # Calculate expected energy consumption\n",
    "        trip_expected = get_expected_based_on_primary_mode_for_one_trip(ct,unit_dist_MCS_df,android_EI_moments_df,ios_EI_moments_df)\n",
    "        expected.append(trip_expected)\n",
    "\n",
    "    # Append the values to expanded_labeled_trips\n",
    "    elt = df.copy()  # elt: expanded labeled trips\n",
    "    elt['expected'] = expected\n",
    "\n",
    "    return elt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_mode_energy_df = compute_all_EC_values_from_primary_mode(expanded_labeled_trips,unit_dist_MCS_df,energy_dict, android_EI_moments_df,ios_EI_moments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_mode_energy_df.expected.sum(), energy_consumption_df.expected.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_mode_energy_df.expected.sum(), energy_consumption_df.expected.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df['primary_expected'] = primary_mode_energy_df.expected\n",
    "energy_consumption_df[['user_labeled', 'primary_expected', 'section_modes', 'mode_confirm','section_distances', 'distance' ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happens with a modeshare approach?\n",
    "The resulting variance is very large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def calculate_EC_by_mode_share(df,android_confusion,ios_confusion)\n",
    "\n",
    "# 1. split into android and ios dataframes\n",
    "# 2. compute for each.\n",
    "import itertools\n",
    "\n",
    "# find a matrix of prob predicted given actual.\n",
    "collapsed_confusion_matrix = cm_handling.collapse_confusion_matrix(android_confusion, rows_to_collapse={\"Train\": [\"Train\"]}, columns_to_collapse={})\n",
    "duration_sensed_as_car_given_actual_ebike = 0.4*collapsed_confusion_matrix.loc['Pilot ebike'].sum()\n",
    "collapsed_confusion_matrix.at['Pilot ebike','bicycling'] -=duration_sensed_as_car_given_actual_ebike\n",
    "collapsed_confusion_matrix.at['Pilot ebike','car'] += duration_sensed_as_car_given_actual_ebike\n",
    "prob_actual_given_predicted_df = collapsed_confusion_matrix/collapsed_confusion_matrix.sum(axis=0)\n",
    "\n",
    "sensed_mode_distances = energy_consumption_df.groupby(\"primary_mode\").sum().distance_miles\n",
    "\n",
    "expected_EC = 0\n",
    "var_EC = 0\n",
    "primary_mode_distance_estimates = {}\n",
    "primary_mode_dist_sd_estimates = {}\n",
    "for primary_mode in sensed_mode_distances.index:\n",
    "    if primary_mode == 'air_or_hsr':\n",
    "        primary_mode = 'train'\n",
    "    primary_mode_distance_estimates[primary_mode] = 0\n",
    "    var_primary_mode_total = 0\n",
    "    for gt_mode in prob_actual_given_predicted_df.index:\n",
    "        prob_gt_mode = prob_actual_given_predicted_df.loc[gt_mode][primary_mode]\n",
    "        expected_distance = prob_gt_mode * sensed_mode_distances[primary_mode] * 1.04  # 1.04 is from unit dist MCS\n",
    "\n",
    "        primary_mode_distance_estimates[primary_mode] += expected_distance        \n",
    "\n",
    "        # n = len(expanded_labeled_trips[expanded_labeled_trips.primary_mode == primary_mode])*\n",
    "        var_in_mode_distance = prob_gt_mode*(1 - prob_gt_mode)*sensed_mode_distances[primary_mode]**2\n",
    "\n",
    "        var_primary_mode_total += var_in_mode_distance    \n",
    "        expected_EC += energy_dict[MODE_MAPPING_DICT[primary_mode]]*expected_distance\n",
    "\n",
    "        var_EC += var_in_mode_distance #*energy_dict[MODE_MAPPING_DICT[primary_mode]]**2\n",
    "\n",
    "\n",
    "    primary_mode_dist_sd_estimates[primary_mode] = np.sqrt(var_primary_mode_total)\n",
    "print(f\"Expected, user labeled {expected_EC:.2f}, {energy_consumption_df.user_labeled.sum():.2f}\")\n",
    "print(f\"sd: {np.sqrt(var_EC):.2f}\")\n",
    "# Based on this, using mode share by distance for EC is not great."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('emission-private-eval')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73ac5b45931ab4dd3f8e07a8d0e5daf0146eed4821bf42374f6ac6fa4af28c83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
