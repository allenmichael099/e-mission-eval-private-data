{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute mean and variance for each program\n",
    "Look at different methods: expected from sections, expected from primary mode\n",
    "Also shows proportions of distance traveled in each mode and an estimate of accuracy for sensing\n",
    "The program specific and true mode specifc bar charts come from this notebook.\n",
    "Makes a percent error table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from uuid import UUID\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/mallen2/alternate_branches/eval-compatible-server/e-mission-server')\n",
    "\n",
    "import emission.storage.timeseries.abstract_timeseries as esta\n",
    "import emission.storage.decorations.trip_queries as esdtq\n",
    "import emission.core.wrapper.user as ecwu\n",
    "\n",
    "import confusion_matrix_handling as cm_handling\n",
    "from confusion_matrix_handling import MODE_MAPPING_DICT\n",
    "import get_EC\n",
    "import helper_functions as hf\n",
    "\n",
    "import sklearn.model_selection as skm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model\n",
    "\n",
    "METERS_TO_MILES = 0.000621371 # 1 meter = 0.000621371 miles\n",
    "ECAR_PROPORTION = 0 #0.01 #~1% of cars on the road are electric.\n",
    "DROVE_ALONE_TO_SHARED_RIDE_RATIO = 1\n",
    "\n",
    "df_EI = pd.read_csv(r'Public_Dashboard/auxiliary_files/energy_intensity.csv') # r stands for raw string, only matters if the path is on Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you've run store_expanded_labeled_trips.ipynb and want to save time vs the cell below\n",
    "%store -r expanded_labeled_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import database_related_functions as drf  # all the emission server functions for this notebook are in here.\n",
    "user_list, os_map, uuid_program_map = drf.get_participants_programs_and_operating_systems()\n",
    "#print(len(user_list), len(os_map), len(uuid_program_map))\n",
    "\n",
    "# Takes 6 to 14 minutes on Macbook Pro for all ceo data + stage + prepilot.\n",
    "# Takes ~ 1 min 45 s to 2 min 45 s on Macbook Pro for all ceo data up to May 2022.\n",
    "expanded_labeled_trips = drf.get_expanded_labeled_trips(user_list)\n",
    "expanded_labeled_trips['os'] = expanded_labeled_trips.user_id.map(os_map)\n",
    "expanded_labeled_trips['program'] = expanded_labeled_trips['user_id'].map(uuid_program_map)\n",
    "\n",
    "expanded_labeled_trips = expanded_labeled_trips.drop(labels = ['source', 'end_fmt_time', 'end_loc', 'raw_trip',\n",
    "    'start_fmt_time', 'start_loc','start_local_dt_year', 'start_local_dt_month', 'start_local_dt_day',\n",
    "    'start_local_dt_hour', 'start_local_dt_minute', 'start_local_dt_second',\n",
    "    'start_local_dt_weekday', 'start_local_dt_timezone',\n",
    "    'end_local_dt_year', 'end_local_dt_month', 'end_local_dt_day',\n",
    "    'end_local_dt_hour', 'end_local_dt_minute', 'end_local_dt_second',\n",
    "    'end_local_dt_weekday', 'end_local_dt_timezone'], axis = 1)\n",
    "\n",
    "expanded_labeled_trips['distance_miles'] = expanded_labeled_trips.distance*METERS_TO_MILES\n",
    "\n",
    "# Group together the prepilot participants\n",
    "prepilot_list = ['84Q9SsrH','cwZazZLJ','CudLAeg8','sxxcLqbK','Q8T7QTXK','5KEGHHuf','e9MaNVU7','7c797MRD','rhBZukxY','k36cxmfA','FmxVf8u6','F3jxHLSW']\n",
    "expanded_labeled_trips['program'] = expanded_labeled_trips.program.replace(prepilot_list, \"prepilot\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_dist_MCS_df = pd.read_csv(\"unit_distance_MCS.csv\").set_index(\"moment\")\n",
    "energy_dict = cm_handling.get_energy_dict(df_EI, units='MWH')\n",
    "\n",
    "sensed_car_EI = hf.find_sensed_car_energy_intensity(energy_dict, ECAR_PROPORTION, DROVE_ALONE_TO_SHARED_RIDE_RATIO)\n",
    "energy_dict.update({\"Car, sensed\": sensed_car_EI})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_labeled_trips = hf.drop_unwanted_trips(expanded_labeled_trips,drop_not_a_trip=False)\n",
    "expanded_labeled_trips = hf.get_primary_modes(expanded_labeled_trips,energy_dict,MODE_MAPPING_DICT)\n",
    "print('Here are the number of labeled trips remaining in each program dataset:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(expanded_labeled_trips.program.value_counts().to_latex())\n",
    "print(f\"all: {len(expanded_labeled_trips)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How far did people travel in each labeled mode?\n",
    "all_mode_distances = expanded_labeled_trips.groupby('mode_confirm').sum().distance_miles\n",
    "all_mode_distance_proportions = all_mode_distances.divide(sum(expanded_labeled_trips.distance_miles))\n",
    "print(all_mode_distance_proportions.sort_values(ascending=False)[0:10].round(4).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough estimates of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What percent of primary mode predictions is correct?\n",
    "# LENIENT MATCHING\n",
    "main_mode_confirms = ['drove_alone','shared_ride','walk','pilot_ebike','bus','bike','train','taxi','free_shuttle', 'not_a_trip']\n",
    "main_modes_df = expanded_labeled_trips[expanded_labeled_trips.mode_confirm.isin(main_mode_confirms)].copy()\n",
    "main_modes_df = main_modes_df[main_modes_df.mode_confirm.notna()]\n",
    "\n",
    "match_count = 0\n",
    "for _,ct in main_modes_df.iterrows():\n",
    "    if (ct['primary_mode'] == 'car') and (ct['mode_confirm'] in ['shared_ride', 'taxi', 'drove_alone']):\n",
    "        match_count += 1\n",
    "    elif (ct['primary_mode'] == 'bicycling') and (ct['mode_confirm'] == 'pilot_ebike'):\n",
    "        match_count += 1\n",
    "    elif (ct['primary_mode'] == 'bus') and (ct['mode_confirm'] == 'free_shuttle'):\n",
    "        match_count += 1\n",
    "    elif MODE_MAPPING_DICT[ct['primary_mode']] == MODE_MAPPING_DICT[ct['mode_confirm']]:\n",
    "        match_count += 1\n",
    "\n",
    "# The version below doesn't count a car prediction as correct for shared ride.\n",
    "#sum(main_modes_df.mode_confirm.map(MODE_MAPPING_DICT)== main_modes_df.primary_mode.map(MODE_MAPPING_DICT))/len(main_modes_df)\n",
    "\n",
    "print(f\"Accuracy by count: {match_count/len(main_modes_df)*100}\")  # 65.75% if we exclude not_a_trip, 63.50% if we include not_a_trip\n",
    "# What fraction of the distance are we correctly predicting?\n",
    "\n",
    "# Note: MODE_MAPPING_DICT[\"no_sensed\"] == MODE_MAPPING_DICT[\"not_a_trip\"]   # both give 'Not a Trip'\n",
    "\n",
    "match_distance = 0\n",
    "for _,ct in main_modes_df.iterrows():\n",
    "    if len(ct['section_modes']) == 0:\n",
    "        print(f\"No sections sensed for a {ct['mode_confirm']} trip.\")\n",
    "    for i,s in enumerate(ct['section_modes']):\n",
    "        if (s == 'car') and (ct['mode_confirm'] in ['shared_ride', 'taxi','drove_alone']):\n",
    "            match_distance += ct['section_distances'][i]\n",
    "        elif (s == 'bicycling') and (ct['mode_confirm'] == 'pilot_ebike'):\n",
    "            match_distance += ct['section_distances'][i]\n",
    "        elif (s == 'bus') and (ct['mode_confirm'] == 'free_shuttle'):\n",
    "            match_count += 1\n",
    "        elif MODE_MAPPING_DICT[s] == MODE_MAPPING_DICT[ct['mode_confirm']]:\n",
    "            match_distance += ct['section_distances'][i]\n",
    "\n",
    "\n",
    "print(f\"Accuracy by distance: {100*match_distance/main_modes_df.distance.sum()}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(all_mode_distance_proportions.keys())\n",
    "# some electric modes I found:\n",
    "# 'electric_car','electric_golf cart','electric_motorcycle','electric_vehicle', 'electric_vehicle, with others'\n",
    "# only a tiny fraction of the distance traveled was labeled as electric car.\n",
    "all_mode_distance_proportions[['electric_car','electric_golf cart','electric_motorcycle','electric_vehicle', 'electric_vehicle, with others']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the confusion matrices and then the EI moments from those.\n",
    "android_confusion = pd.read_csv(\"android_confusion.csv\").set_index('gt_mode')\n",
    "ios_confusion = pd.read_csv(\"ios_confusion.csv\").set_index('gt_mode')\n",
    "\n",
    "android_confusion = cm_handling.collapse_confusion_matrix(android_confusion, rows_to_collapse={\"Train\": [\"Train\"]}, columns_to_collapse={})\n",
    "ios_confusion = cm_handling.collapse_confusion_matrix(ios_confusion, rows_to_collapse={\"Train\": [\"Train\"]}, columns_to_collapse={})\n",
    "\n",
    "expanded_labeled_trips['distance_miles'] = expanded_labeled_trips.distance*METERS_TO_MILES\n",
    "EI_length_cov = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you forget this step, the error for expected may be different, \n",
    "# since you might be relying on a different saved version of the EI_moments_dataframe\n",
    "android_EI_moments_df = cm_handling.get_conditional_EI_expectation_and_variance(android_confusion,energy_dict)\n",
    "ios_EI_moments_df = cm_handling.get_conditional_EI_expectation_and_variance(ios_confusion,energy_dict)\n",
    "os_EI_moments_map = {'ios': ios_EI_moments_df, 'android': android_EI_moments_df}\n",
    "energy_consumption_from_sections_df= get_EC.compute_all_EC_values(expanded_labeled_trips,unit_dist_MCS_df,energy_dict,android_EI_moments_df,ios_EI_moments_df, \\\n",
    "    EI_length_cov, print_info=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent error table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percent errors all together: expected based on sections, expected based on primary mode, and predicted\n",
    "energy_consumption_from_primary_mode_df = get_EC.compute_all_EC_values_from_primary_mode(expanded_labeled_trips, unit_dist_MCS_df, energy_dict, android_EI_moments_df,ios_EI_moments_df)\n",
    "\n",
    "program_percent_error_map = hf.get_program_percent_error_map(energy_consumption_from_sections_df, 'expected')\n",
    "percent_error_df = pd.DataFrame(program_percent_error_map,index=[0])\n",
    "percent_error_df = percent_error_df.append(hf.get_program_percent_error_map(energy_consumption_from_primary_mode_df, 'expected'), ignore_index=True)\n",
    "percent_error_df = percent_error_df.append(hf.get_program_percent_error_map(energy_consumption_from_sections_df, 'predicted'), ignore_index=True)\n",
    "\n",
    "percent_error_df = percent_error_df.round(2)\n",
    "percent_error_df['estimation_method'] = ['expected from sections', 'expected from primary mode', 'prediction only']\n",
    "print(percent_error_df.set_index('estimation_method').to_latex())\n",
    "#print(percent_error_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trips = expanded_labeled_trips.program.value_counts()\n",
    "n_trips[\"all\"] = sum(n_trips)\n",
    "pd.DataFrame({\"Number of trips\": n_trips, \"Percent error\": pd.Series(program_percent_error_map)}).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(expanded_labeled_trips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using aggregate distances when computing variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell plots the user labeled and expected aggregate energy consumptions on the left and right, respectively.\n",
    "program_n_sd_map_aggregate_distance = hf.plot_estimates_with_sd_by_program(energy_consumption_from_sections_df,os_EI_moments_map,unit_dist_MCS_df,variance_method=\"aggregate_section_distances\")\n",
    "print(f\"number of standard deviations from mean: {program_n_sd_map_aggregate_distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_n_sd_map_aggregate_distance = hf.plot_estimates_with_sd_by_program(energy_consumption_from_primary_mode_df,os_EI_moments_map,unit_dist_MCS_df,variance_method=\"aggregate_primary_mode_distances\")\n",
    "print(f\"number of standard deviations from mean: {program_n_sd_map_aggregate_distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the sum of individual variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell plots the user labeled and expected aggregate energy consumptions on the left and right, respectively.\n",
    "# It uses the old method of getting aggregate variance (add up individual variances, no covariance term).\n",
    "program_n_sd_map_individual_trips = hf.plot_estimates_with_sd_by_program(energy_consumption_from_sections_df,os_EI_moments_map,unit_dist_MCS_df,variance_method=\"independent individual trips\")\n",
    "print(f\"number of standard deviations from mean: {program_n_sd_map_individual_trips}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar chart version of mean plus or minus 1 standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = energy_consumption_from_sections_df.copy()\n",
    "x_labels = list(df.program.unique()) + ['all']\n",
    "\n",
    "user_labeled_EC_list = []\n",
    "expected_EC_list = []\n",
    "standard_deviation_list = []\n",
    "user_sd_list = []\n",
    "\n",
    "# For each program, find the aggregate EC with user labels or with sensed labels.\n",
    "for program in df.program.unique():\n",
    "    program_df = df[df.program == program]\n",
    "    user_labeled_EC_list.append(program_df.user_labeled.sum())\n",
    "    expected_EC_list.append(program_df.expected.sum())\n",
    "    EC_var, _ = get_EC.compute_aggregate_variance_with_total_distance_from_sections(program_df, os_EI_moments_map,unit_dist_MCS_df)\n",
    "    standard_deviation_list.append(np.sqrt(EC_var))\n",
    "    user_sd_list.append(np.sqrt(program_df.user_var.sum()))\n",
    "\n",
    "# Find the totals for all programs\n",
    "expected_EC_list.append(df.expected.sum())\n",
    "user_labeled_EC_list.append(df.user_labeled.sum())\n",
    "user_sd_list.append(np.sqrt(df.user_var.sum()))\n",
    "\n",
    "# Beware: this function currently returns two things\n",
    "EC_var, _ = get_EC.compute_aggregate_variance_with_total_distance_from_sections(df, os_EI_moments_map,unit_dist_MCS_df)\n",
    "standard_deviation_list.append(np.sqrt(EC_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=len(x_labels)\n",
    "x_range = np.arange(n)\n",
    "width = 0.3\n",
    "\n",
    "\n",
    "  \n",
    "plt.bar(x_range, user_labeled_EC_list, yerr = user_sd_list, color = 'tab:blue', width = width, label= 'user labeled', capsize=5)\n",
    "plt.bar(x_range + width, expected_EC_list, yerr = standard_deviation_list, color = 'tab:orange', width = width, label = 'inferred', capsize= 5)\n",
    "  \n",
    "plt.xlabel(\"Program\",fontsize = 14)\n",
    "plt.ylabel(\"Energy consumption (MWH)\",fontsize = 14)\n",
    "plt.title(\"Cumulative energy consumption by program from user labels vs from inferred labels\",fontsize = 15)\n",
    "  \n",
    "plt.xticks(x_range + width/2, x_labels, fontsize= 12)\n",
    "plt.legend(prop={'size': 12})\n",
    "plt.rcParams[\"figure.figsize\"] = (10,8)\n",
    "plt.show()\n",
    "\n",
    "# alternative display, one program per subplot: hf.plot_aggregate_EC_bar_chart(energy_consumption_from_sections_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy consumption by actual mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.plot_energy_consumption_by_mode(energy_consumption_from_sections_df, \"all programs\", main_mode_labels = ['drove_alone','shared_ride','walk','pilot_ebike','bus','bike','train','taxi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now try with a Bayes update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_probs = hf.construct_prior_dict({\"Car, sensed\": 0.85, \"Pilot ebike\": 0.05})\n",
    "\n",
    "android_EI_moments_with_Bayes_update_df = cm_handling.get_Bayesian_conditional_EI_expectation_and_variance(android_confusion,energy_dict, prior_probs)\n",
    "ios_EI_moments_with_Bayes_update_df = cm_handling.get_Bayesian_conditional_EI_expectation_and_variance(ios_confusion,energy_dict, prior_probs)\n",
    "os_EI_moments_with_Bayes_update_map = {'ios': ios_EI_moments_with_Bayes_update_df, 'android': android_EI_moments_with_Bayes_update_df}\n",
    "energy_consumption_with_Bayes_update_df = get_EC.compute_all_EC_values(expanded_labeled_trips,unit_dist_MCS_df,energy_dict,\\\n",
    "    android_EI_moments_with_Bayes_update_df,\\\n",
    "    ios_EI_moments_with_Bayes_update_df, \\\n",
    "    EI_length_cov, print_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate distance method\n",
    "# This cell plots the user labeled and expected aggregate energy consumptions on the left and right, respectively. \n",
    "program_n_sd_map = hf.plot_estimates_with_sd_by_program(energy_consumption_with_Bayes_update_df,os_EI_moments_with_Bayes_update_map, unit_dist_MCS_df, variance_method='aggregate_distance')\n",
    "print(f\"number of standard deviations from mean: {program_n_sd_map}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial covariance method\n",
    "program_n_sd_map = hf.plot_estimates_with_sd_by_program(energy_consumption_df,os_EI_moments_map,unit_dist_MCS_df,variance_method=\"aggregate_distance\")\n",
    "print(f\"number of standard deviations from mean: {program_n_sd_map}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the proportions of each mode in mobilitynet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mobilitynet_trips = android_confusion + ios_confusion\n",
    "durations_in_modes = all_mobilitynet_trips.sum(axis=1)\n",
    "mobility_net_mode_proportions = durations_in_modes/all_mobilitynet_trips.sum().sum() #this gives the proportions of each mode in mobilitynet\n",
    "print(mobility_net_mode_proportions.round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility_net_mode_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration that dividing each android confusion column by its column sum is \n",
    "# equivalent to assuming that the data has the same prior mode distribution as the android trips in mobility net\n",
    "android_confusion = pd.read_csv(\"android_confusion.csv\").set_index('gt_mode')#+ ios_confusion\n",
    "\n",
    "durations_in_modes = android_confusion.sum(axis=1)\n",
    "prior_mode_probs = durations_in_modes/all_mobilitynet_trips.sum().sum()\n",
    "\n",
    "p_predicted_given_actual = android_confusion.divide(android_confusion.sum(axis=1), axis='rows')\n",
    "\n",
    "likelihood_times_priors = p_predicted_given_actual.multiply(pd.Series(prior_mode_probs), axis='rows')\n",
    "normalizing_constants = likelihood_times_priors.sum(axis='rows')\n",
    "prob_actual_given_predicted_df = likelihood_times_priors.divide(normalizing_constants, axis='columns').copy()\n",
    "prob_actual_given_predicted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ios_confusion = pd.read_csv(\"ios_confusion.csv\").set_index('gt_mode')\n",
    "android_confusion = pd.read_csv(\"android_confusion.csv\").set_index('gt_mode')#+ ios_confusion\n",
    "\n",
    "all_mobilitynet_trips = android_confusion + ios_confusion\n",
    "durations_in_modes = all_mobilitynet_trips.sum(axis=1)\n",
    "prior_mode_probs = durations_in_modes/all_mobilitynet_trips.sum().sum()\n",
    "\n",
    "p_predicted_given_actual = android_confusion.divide(android_confusion.sum(axis=1), axis='rows')\n",
    "\n",
    "likelihood_times_priors = p_predicted_given_actual.multiply(pd.Series(prior_mode_probs), axis='rows')\n",
    "normalizing_constants = likelihood_times_priors.sum(axis='rows')\n",
    "prob_actual_given_predicted_df = likelihood_times_priors.divide(normalizing_constants, axis='columns').copy()\n",
    "prob_actual_given_predicted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_energy_consumption_by_mode(energy_consumption_df,program_name, main_mode_labels = ['drove_alone','shared_ride','walk','pilot_ebike','bus','bike','train','taxi','free_shuttle']):\n",
    "    df = energy_consumption_df.copy()\n",
    "    program_main_mode_labels = [x for x in main_mode_labels if x in df.mode_confirm.unique()] # 4c doesn't have train before May 2022.\n",
    "\n",
    "    program_main_modes_EC = df.groupby('mode_confirm').sum().loc[program_main_mode_labels]\n",
    "    program_main_modes_EC = program_main_modes_EC[['expected','user_labeled']] # 'predicted',\n",
    "\n",
    "    program_main_modes_EC.plot(kind='barh')\n",
    "    program_percent_error_expected = 100*hf.relative_error(df.expected.sum(),df.user_labeled.sum())\n",
    "    plt.xlabel('Energy consumption (kWH)')\n",
    "    plt.ylabel('user labeled mode')\n",
    "    plt.title(f\"Energy consumption estimates by user labeled mode for {program_name}\\nCustom mode labels not shown\\n(full % error for expected: {program_percent_error_expected:.2f})\")\n",
    "\n",
    "plot_energy_consumption_by_mode(energy_consumption_from_sections_df,'all CEO + stage', main_mode_labels = ['drove_alone','shared_ride','walk','pilot_ebike','bus','bike','train','taxi','free_shuttle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what percent of all ceo trips are ebike?\n",
    "expanded_labeled_trips.groupby('mode_confirm').sum()['distance']['pilot_ebike']/expanded_labeled_trips.distance.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate variance with sections or calculate mean with primary mode.\n",
    "Distance in each mode gets distributed differently if you look at primary mode instead of sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_based_on_sections, distance_in_mode = get_EC.compute_aggregate_variance_with_total_distance_from_sections(expanded_labeled_trips, os_EI_moments_map, unit_dist_MCS_df)\n",
    "\n",
    "# the version that I've been using takes the total distance in miles for the trip and groups by primary mode.\n",
    "var_based_on_primary_modes = get_EC.compute_aggregate_variance(expanded_labeled_trips, os_EI_moments_map, unit_dist_MCS_df)\n",
    "np.sqrt(var_based_on_sections), np.sqrt(var_based_on_primary_modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(sum(distance_in_mode['android'].values()) + sum(distance_in_mode['ios'].values()),2), round(expanded_labeled_trips.distance_miles.sum(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_primary_mode_distance_vs_section_distance_df(expanded_labeled_trips, distance_in_mode, os):\n",
    "\n",
    "    primary_distances= expanded_labeled_trips[expanded_labeled_trips.os == os].groupby(\"primary_mode\").distance_miles.sum()\n",
    "    primary_vs_section_df = pd.DataFrame(primary_distances)\n",
    "\n",
    "    primary_vs_section_df[\"section_based_distance\"] = primary_vs_section_df.index.map(distance_in_mode[os])\n",
    "    return primary_vs_section_df\n",
    "\n",
    "get_primary_mode_distance_vs_section_distance_df(expanded_labeled_trips,distance_in_mode, \"android\").round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_primary_mode_distance_vs_section_distance_df(expanded_labeled_trips,distance_in_mode, \"ios\").round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_mode_energy_df = get_EC.compute_all_EC_values_from_primary_mode(expanded_labeled_trips,unit_dist_MCS_df,energy_dict, android_EI_moments_df,ios_EI_moments_df)\n",
    "primary_mode_energy_df.expected.sum(), energy_consumption_df.expected.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df['primary_expected'] = primary_mode_energy_df.expected\n",
    "energy_consumption_df[['user_labeled', 'expected','primary_expected', 'section_modes', 'mode_confirm','section_distances', 'distance' ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happens with a modeshare approach?\n",
    "The resulting variance is very large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def calculate_EC_by_mode_share(df,android_confusion,ios_confusion)\n",
    "\n",
    "# 1. split into android and ios dataframes\n",
    "# 2. compute for each.\n",
    "import itertools\n",
    "\n",
    "# find a matrix of prob predicted given actual.\n",
    "collapsed_confusion_matrix = cm_handling.collapse_confusion_matrix(android_confusion, rows_to_collapse={\"Train\": [\"Train\"]}, columns_to_collapse={})\n",
    "duration_sensed_as_car_given_actual_ebike = 0.4*collapsed_confusion_matrix.loc['Pilot ebike'].sum()\n",
    "collapsed_confusion_matrix.at['Pilot ebike','bicycling'] -=duration_sensed_as_car_given_actual_ebike\n",
    "collapsed_confusion_matrix.at['Pilot ebike','car'] += duration_sensed_as_car_given_actual_ebike\n",
    "prob_actual_given_predicted_df = collapsed_confusion_matrix/collapsed_confusion_matrix.sum(axis=0)\n",
    "\n",
    "sensed_mode_distances = energy_consumption_df.groupby(\"primary_mode\").sum().distance_miles\n",
    "\n",
    "expected_EC = 0\n",
    "var_EC = 0\n",
    "primary_mode_distance_estimates = {}\n",
    "primary_mode_dist_sd_estimates = {}\n",
    "for primary_mode in sensed_mode_distances.index:\n",
    "    if primary_mode == 'air_or_hsr':\n",
    "        primary_mode = 'train'\n",
    "    primary_mode_distance_estimates[primary_mode] = 0\n",
    "    var_primary_mode_total = 0\n",
    "    for gt_mode in prob_actual_given_predicted_df.index:\n",
    "        prob_gt_mode = prob_actual_given_predicted_df.loc[gt_mode][primary_mode]\n",
    "        expected_distance = prob_gt_mode * sensed_mode_distances[primary_mode] * 1.04  # 1.04 is from unit dist MCS\n",
    "\n",
    "        primary_mode_distance_estimates[primary_mode] += expected_distance        \n",
    "\n",
    "        # n = len(expanded_labeled_trips[expanded_labeled_trips.primary_mode == primary_mode])*\n",
    "        var_in_mode_distance = prob_gt_mode*(1 - prob_gt_mode)*sensed_mode_distances[primary_mode]**2\n",
    "\n",
    "        var_primary_mode_total += var_in_mode_distance    \n",
    "        expected_EC += energy_dict[MODE_MAPPING_DICT[primary_mode]]*expected_distance\n",
    "\n",
    "        var_EC += var_in_mode_distance #*energy_dict[MODE_MAPPING_DICT[primary_mode]]**2\n",
    "\n",
    "\n",
    "    primary_mode_dist_sd_estimates[primary_mode] = np.sqrt(var_primary_mode_total)\n",
    "print(f\"Expected, user labeled {expected_EC:.2f}, {energy_consumption_df.user_labeled.sum():.2f}\")\n",
    "print(f\"sd: {np.sqrt(var_EC):.2f}\")\n",
    "# Based on this, using mode share by distance for EC is not great."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('emission-private-eval')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73ac5b45931ab4dd3f8e07a8d0e5daf0146eed4821bf42374f6ac6fa4af28c83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
